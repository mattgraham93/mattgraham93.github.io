---
title: "DA410_Exam2_MattGraham"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---


```{r Imports, message=FALSE}
library(nnspat)  # used for dist2full()
library("dplyr")  # used to select numeric datatypes
library("ggplot2")
library(reshape)  # used for melting matricies
library(klaR)
library(ggvis)
library(class)
library(gmodels)
library(MASS)
library(readxl)
library(psych)
library(corrplot)
library(lavaan)
library(semPlot)
library(semTable)
library(kutils)
```

## Problem 1
Get data
```{r}
cov.mat <- data.frame(c(5, 0, 0), c(0, 9,0), c(0,0,9))
cov.mat
```


### A) Find eigenvalues and vectors
```{r}
cov.mat.vals <- eigen(cov.mat)$values
cov.mat.vals
```

```{r}
cov.mat.vects <- eigen(cov.mat)$vectors
cov.mat.vects
```

### B) Find variance explained

```{r}

for (r in cov.mat.vals) {
  print(r/sum(cov.mat.vals))
}

```
We can see that of our eigen values, ~80% of our variance is explained with 2 dimensions, while ~20% is explained with 1 dimension. This can be seen below.

#### Plot
```{r}
plot(cov.mat.vals/sum(cov.mat.vals), xlab = 'Number of components', ylab='Eigen size', main='Plot of dimension variance')
```

###C) Decision
Ultimately, we will want to select 2 components in our analysis.


## Problem 2

Assumption check:

Variables used should be metric.  Dummy variables can also be considered, but only in special cases. -> check

Sample size: Sample size should be more than 200. -> check

Homogeneous sample: A sample should be homogenous.  Violation of this assumption increases the 
sample size as the number of variables increases.  Reliability analysis is conducted to check the 
homogeneity between variables. 

Correlation: At least 0.30 correlations are required between the research variables. 
```{r}

french <- c(1, .44, .41, .29, .33, .25)
english <- c(.44, 1, .35, .35, .32, .33)
history <- c(.41, .35, 1, .16, .19, .18)
arithmetic <- c(.29, .35, .16, 1, .59, .47)
algebra <- c(.33, .32, .19, .59, 1, .46)
geometry <- c(.25, .33, .18, .47, .46, 1)

subject.cor <- cbind(french, english, history, arithmetic, algebra, geometry)
row.names(subject.cor) <- c('french', 'english', 'history', 'arithmetic', 'algebra', 'geometry')
as.data.frame(subject.cor)
```
We have a few correlations that are unable to be compared, and will be noted through analysis

Since we do not have a raw dataset, we assume there are no outliers.

### Running fa
```{r}
solution <- fa(r = subject.cor, nfactors = 2, rotate = "oblimin", fm="pa")
solution
```


Overall, our model does a great job explaining ~90% of variation when using 2 factors. Our most-ideal values to model from would be arithmetic and algebra. We can also see in our console output that hypothesis tests with 2 factors are sufficient. Neither of these have correlations below .30.


## Problem 3
Get data
```{r}
food.stuff <- read.table("C:/mattgraham93.github.io/school/22_3_DA410/data/foodstuff.dat", header=TRUE)
food.stuff <- food.stuff[-1]
food.stuff
```

### a. Determine factors to use

```{r}
library(factoextra)
food.stuff.pca <- prcomp(food.stuff)
fviz_eig(food.stuff.pca)
```

We will ultimately use 2 dimensions when concluding our analysis.

### B - obtaining loadings
```{r}
S <- cov(food.stuff)
R <- cor(food.stuff)
```

S
```{r}
as.data.frame(S)
```

R
```{r}
as.data.frame(R)
```
Get eigenvalues and eigenvectors of S and R
```{r}
eig.S <- eigen(S)
eig.R <- eigen(R)
```

Eigen S
```{r}
eig.S
```
Eigen R
```{r}
eig.R
```
### c. Obtain scores
```{r}

for (r in eig.R$values) {
  print(r/sum(eig.R$values))
}

```
We can see that of our eigen values, ~65% of our variance is explained with just two dimensions, and inerestingly enough going with all 5 shows almost no meaningful value. We can see this below.

#### Plot
```{r}
plot(eig.R$values/sum(eig.R$values), xlab = 'Number of components', ylab='Eigen size', main='Plot of dimension variance')
```

### e. Interpretation
Over the impact of foods' macros pertaining to total energy, as we model our data, we can conclude that most of our variation happens within the first 2 measures compared to subsequent ones. This makes sense as protein and fat are our primary determinate for overall macro tracking and impact caloric intake.


## Problem 4
```{r}
scores <- read.table("C:/mattgraham93.github.io/school/22_3_DA410/data/test_score.dat", header=TRUE)
scores <- scores[-1]
scores
```

### Hotelling's test

```{r warning=FALSE}
summary(manova(cbind(math, reading) ~sex, data=scores), test="Hotelling")
```

#### Hotelling's Analysis
At alpha = 0.05 and p-value < 0.05, we can conclude there is sufficient evidence to state there are differences between mean math and reading scores between the recorded sexes. 



## Problem 5
Get data
```{r}
glucose <- read.table("C:/mattgraham93.github.io/school/22_3_DA410/data/T3_5_DIABETES.DAT", header=FALSE)[1:34,]
glucose <- glucose[-1]
colnames(glucose) <- c('rel_wt', 'fst_pls_glu', 'gl_int', 'ins_resp', 'ins_resist')  

ys <- glucose[1:2]
xs <- glucose[3:5]

glucose
```

Find means
```{r}
x.bar <- colMeans(xs)
x.bar
```

```{r}
y.bar <- colMeans(ys)
y.bar
```


### a - Find canonical correlations

```{r}
cancor2<-function(x,y,dec=4){ 
#Canonical Correlation Analysis to mimic SAS PROC CANCOR output. 
#Basic formulas can be found in Chapter 10 of Mardia, Kent, and Bibby (1979). 
# The approximate F statistic is exercise 3.7.6b. 
    x<-as.matrix(x)
    y<-as.matrix(y) 
    
    n<-dim(x)[1]
    q1<-dim(x)[2]
    q2<-dim(y)[2]
    q<-min(q1,q2) 
    
    S11<-cov(x)
    S12<-cov(x,y)
    S21<-t(S12)
    S22<-cov(y) 
    
    E1<-eigen(solve(S11)%*%S12%*%solve(S22)%*%S21)
    E2<-eigen(solve(S22)%*%S21%*%solve(S11)%*%S12) 
    
    rsquared<-as.double(E1$values[1:q]) 
    
    LR<-NULL;pp<-NULL;qq<-NULL;tt<-NULL 
    
    for (i in 1:q){ 
        LR<-c(LR,prod(1-rsquared[i:q])) 
        pp<-c(pp,q1-i+1) 
        qq<-c(qq,q2-i+1) 
        tt<-c(tt,n-1-i+1)} 
    
    m<-tt-0.5*(pp+qq+1);lambda<-(1/4)*(pp*qq-2);s<-sqrt((pp^2*qq^2-4)/(pp^2+qq^2-5)) 
    F<-((m*s-2*lambda)/(pp*qq))*((1-LR^(1/s))/LR^(1/s))
    df1<-pp*qq;df2<-(m*s-2*lambda)
    pval<-1-pf(F,df1,df2) 
    outmat<-round(cbind(sqrt(rsquared),rsquared,LR,F,df1,df2,pval),dec) 
      
    colnames(outmat) <- list("R","RSquared","LR","ApproxF","NumDF","DenDF","pvalue")
    rownames(outmat) <- as.character(1:q)
    xrels<-round(cor(x,x%*%E1$vectors)[,1:q],dec) 
    colnames(xrels)<-apply(cbind(rep("U",q),as.character(1:q)),1,paste,collapse="")
    yrels<-round(cor(y,y%*%E2$vectors)[,1:q],dec) 
    colnames(yrels)<- apply(cbind(rep("V",q),as.character(1:q)),1,paste,collapse="")
    list(Summary=outmat,
         a.Coefficients=E1$vectors,
         b.Coefficients=E2$vectors, 
         XUCorrelations=xrels,YVCorrelations=yrels
     ) 
   }  
## END FUNCTION 
################################################# 
```


### b - Find standard coefficients
For canonical variables

Fasting coefficients
```{r}
before.coefficients <- cancor2(xs, ys)$a.Coefficients
after.coefficients <- cancor2(xs, ys)$b.Coefficients

diag(before.coefficients)
```
Post-consumption coefficients
```{r}
diag(after.coefficients)
```

### c - Test significance for reach canonical correlation
```{r}
 
cancor2(xs, ys) 
 
# It produces two other pieces of information:  An F-test for the  
# significance of each canonical correlation, and the correlations between  
# the original variables and the corresponding canonical variates. 
```

#### Interpretation
Given all our p-values < 0.05, there is enough evidence to conclude that there is at least one non-zero canonical correlation between relative weight and plasma glucose across glucose intolerance, insulin response to oral glucose, and insulin resistance.This means our subjects had different responses to ingesting glucose. This makes sense as diabetes and insulin are directly correlated.

## Problem 6

```{r}
hematology <- read.csv('C:/mattgraham93.github.io/school/22_3_DA410/data/hematology.csv', header=TRUE)
hematology
```

```{r}
pairs(hematology[-1])
```

Normalizing
```{r}
z <- hematology[,-c(1,1)]
means <- apply(z,2,mean)
sds <- apply(z,2,sd)
nor <- scale(z,center=means,scale=sds)

distance = dist(nor)
```


Plotting
```{r}
mydata.hclust = hclust(distance)
plot(mydata.hclust)
plot(mydata.hclust,labels=hematology$Observation.number,main='Default from hclust')
plot(mydata.hclust,hang=-1, labels=hematology$Observation.number,main='Default from hclust')
```



Average linkage
```{r}
mydata.hclust<-hclust(distance,method="average") 
plot(mydata.hclust,hang=-1) 
```


